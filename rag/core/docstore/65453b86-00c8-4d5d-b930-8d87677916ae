{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"producer": "macOS Version 15.6.1 (Build 24G90) Quartz PDFContext", "creator": "PScript5.dll Version 5.2.2", "creationdate": "D:20250906194222Z00'00'", "title": "Microsoft Word - Basic Ratemaking_Version 5_May 2016_2.docx", "author": "KAREN345", "moddate": "D:20250906194222Z00'00'", "source": "/home/hugo/code/aria/assets/actuarial/5_Werner_Modlin_stripped_EX_appendices.pdf", "total_pages": 313, "page": 164, "page_label": "165", "pdf_path": "/home/hugo/code/aria/assets/actuarial/5_Werner_Modlin_stripped_EX_appendices.pdf", "source_name": "Werner Entire Text"}, "page_content": "Linear models also assume that the random variable, \u03b5, is normally distributed with a mean of zero and \nconstant variance, \u03c32.   \nThe aim of the linear model is to find the parameter estimates, which, when applied to the chosen model \nform, produce the observed data with the highest probability.  The function used to achieve this aim is \nusually the likelihood function (or equivalently the log-likelihood).  Maximum likelihood relies on linear \nalgebra to solve a system of equations.  In practice, due to the high volume of observations in \nclassification ratemaking datasets, numerical techniques such as multi-dimensional Newton-Raphson \nalgorithms are employed.  These techniques find the maximum of a function by finding a zero in the \nfunction\u2019s first derivative.  Also note that in the specific case of linear models, the likelihood function is \nequivalent to minimizing the sum of squared error between actual and indicated.", "type": "Document"}}