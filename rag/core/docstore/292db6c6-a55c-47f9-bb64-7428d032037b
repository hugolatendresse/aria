{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"producer": "macOS Version 15.6.1 (Build 24G90) Quartz PDFContext", "creator": "PScript5.dll Version 5.2.2", "creationdate": "D:20250906194042Z00'00'", "title": "Estimating Unpaid Claims Using Basic Techniques", "author": "Jacqueline Friedland, KPMG LLP", "moddate": "D:20250906194042Z00'00'", "source": "/home/hugo/code/aria/assets/actuarial/5_Friedland_stripped_EX_appendices.pdf", "total_pages": 365, "page": 199, "page_label": "200", "pdf_path": "/home/hugo/code/aria/assets/actuarial/5_Friedland_stripped_EX_appendices.pdf", "source_name": "Friedland Entire Text"}, "page_content": "severities for the most recent accident years. Frequency-severity projections can provide a \nvaluable alternative for the actuary, particularly for the most recent accident years. \n \nOne of the most important advantages of a frequency-severity approach is the potential to gain \ngreater insight into the claims process, both with respect to the rate of claims reporting and \nsettlement and the average dollar value of claims. Another important strength of many frequency-\nseverity methods is that they can be used with paid claims data only so that they are independent \nof case outstanding. Thus, changes in case outstanding philosophy or procedures will not affect \nthe results of such techniques.  \n \nAn often-cited advantage of frequency-severity based techniques is the ability to explicitly reflect \ninflation in the projection methodology instead of assuming that past development patterns will \nproperly account for inflationary forces. However, the advantage of directly incorporating \ninflation can also be a disadvantage as the method is highly sensitive to the inflation assumption. \nIf the inflation assumption proves incorrect, then the estimate of unpaid claims will likely also \nprove incorrect. We suggest that you test the sensitivity of the inflation assumption in several of \nthe examples presented in this chapter. \n \nOne of the most common reasons that actuaries do not use frequency-severity methods is simply \nthe unavailability of data. Another reason that many actuaries do not use these methods is because \nchanges in the definition of claim counts, claims processing, or both can invalidate the underlying \nassumption that future claim count development will be similar to historical claim count \ndevelopment. Joseph O. Thorne discusses the influence of changes in the definition of a claim in \nhis review of the Berquist and Sherman paper \u201cLoss Reserve Adequacy Testing: A \n212", "type": "Document"}}