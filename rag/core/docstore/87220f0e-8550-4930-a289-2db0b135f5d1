{"lc": 1, "type": "constructor", "id": ["langchain", "schema", "document", "Document"], "kwargs": {"metadata": {"producer": "macOS Version 15.6.1 (Build 24G90) Quartz PDFContext", "creator": "PScript5.dll Version 5.2.2", "creationdate": "D:20250906194222Z00'00'", "title": "Microsoft Word - Basic Ratemaking_Version 5_May 2016_2.docx", "author": "KAREN345", "moddate": "D:20250906194222Z00'00'", "source": "/home/hugo/code/aria/assets/actuarial/5_Werner_Modlin_stripped_EX_appendices.pdf", "total_pages": 313, "page": 170, "page_label": "171", "pdf_path": "/home/hugo/code/aria/assets/actuarial/5_Werner_Modlin_stripped_EX_appendices.pdf", "source_name": "Werner Entire Text"}, "page_content": "Chapter 10:  Multivariate Classification \n182 \n \n10.4 Model Validation \n \nConsiderable disparity between actual and expected results on the hold-out sample may indicate that the \nmodel is over or under-fitting.  If the modeler retains variables in the model that reflect a non-systematic \neffect on the response variable (i.e., noise) or over-specifies the model with high order polynomials, the \nresult is over-fitting.  Such a model will replicate the historical data very well (including the noise) but is \nnot going to predict future outcomes reliably (as the future experience will most likely not have the same \nnoise).  Conversely, if the model is missing important statistical effects (the extreme being a model that \ncontains no explanatory variables and fits to the overall mean), the result is under-fitting.  This model will \npredict future outcomes (e.g., in the extreme case mentioned above, the future mean) reliably but hardly \nhelp the modeler explain what is driving the result. \nAppendix F includes additional examples and more details. \n \t\n0\n5000\n10000\n15000\n20000\n25000\n30000\n35000\n40000\n45000\n50000\n-0.1\n0\n0.1\n0.2\n0.3\n0.4\n0.5\n0.6\n0.7\nExposure\nWeighted average frequency\nExpected frequency from GLM\nExposure\nHistorical \nfrequency\nExpected \nfrequency", "type": "Document"}}